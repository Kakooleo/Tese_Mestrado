@article{kaewunruen12008dynamic,
  title={Dynamic properties of railway track and its components: a state-of-the-art review},
  author={Kaewunruen$^1$, Sakdirat and Remennikov$^1$, Alex M},
  journal={New research on acoustics},
  pages={197},
  year={2008},
  publisher={Nova Publishers}
}

@book{attoh2017big,
  title={Big data and differential privacy: analysis strategies for railway track engineering},
  author={Attoh-Okine, Nii O},
  year={2017},
  publisher={John Wiley \& Sons}
}

@article{Tsai_Lai_Chao_Vasilakos_2015, 
title={Big Data Analytics: A survey}, 
volume={2}, DOI={10.1186/s40537-015-0030-3}, 
number={1}, 
journal={Journal of Big Data}, author={Tsai, Chun-Wei and Lai, Chin-Feng and Chao, Han-Chieh and Vasilakos, Athanasios V.}, year={2015}, month={Oct}} 

@article{Zamanzadeh_Darban_Webb_Pan_Aggarwal_Salehi_2024, title={Deep learning for TIME SERIES ANOMALY DETECTION: A survey}, volume={57}, DOI={10.1145/3691338}, number={1}, journal={ACM Computing Surveys}, author={Zamanzadeh Darban, Zahra and Webb, Geoffrey I. and Pan, Shirui and Aggarwal, Charu and Salehi, Mahsa}, year={2024}, month={Oct}, pages={1–42}}

@article{Choi_Yi_Park_Yoon_2021, title={Deep learning for anomaly detection in time-series data: Review, analysis, and Guidelines}, volume={9}, DOI={10.1109/access.2021.3107975}, journal={IEEE Access}, author={Choi, Kukjin and Yi, Jihun and Park, Changhwa and Yoon, Sungroh}, year={2021}, pages={120043–120065}}

@article{Blázquez-García_Conde_Mori_Lozano_2021, title={A review on outlier/anomaly detection in time series data}, volume={54}, DOI={10.1145/3444690}, number={3}, journal={ACM Computing Surveys}, author={Blázquez-García, Ane and Conde, Angel and Mori, Usue and Lozano, Jose A.}, year={2021}, month={Apr}, pages={1–33}}

@article{Samariya_Thakkar_2021, title={A comprehensive survey of Anomaly Detection Algorithms}, DOI={10.1007/s40745-021-00362-9}, journal={Annals of Data Science}, author={Samariya, Durgesh and Thakkar, Amit}, year={2021}, month={Nov}} 

@article{Grubbs_1969, title={Procedures for detecting outlying observations in samples}, volume={11}, DOI={10.2307/1266761}, number={1}, journal={Technometrics}, author={Grubbs, Frank E.}, year={1969}, month={Feb}, pages={1}} 

@article{AGATONOVICKUSTRIN2000717,
title = {Basic concepts of artificial neural network (ANN) modeling and its application in pharmaceutical research},
journal = {Journal of Pharmaceutical and Biomedical Analysis},
volume = {22},
number = {5},
pages = {717-727},
year = {2000},
issn = {0731-7085},
doi = {https://doi.org/10.1016/S0731-7085(99)00272-1},
url = {https://www.sciencedirect.com/science/article/pii/S0731708599002721},
author = {S Agatonovic-Kustrin and R Beresford},
keywords = {Artificial neural network (ANN), Pharmaceutical research, Artificial intelligence (AI)},
abstract = {Artificial neural networks (ANNs) are biologically inspired computer programs designed to simulate the way in which the human brain processes information. ANNs gather their knowledge by detecting the patterns and relationships in data and learn (or are trained) through experience, not from programming. An ANN is formed from hundreds of single units, artificial neurons or processing elements (PE), connected with coefficients (weights), which constitute the neural structure and are organised in layers. The power of neural computations comes from connecting neurons in a network. Each PE has weighted inputs, transfer function and one output. The behavior of a neural network is determined by the transfer functions of its neurons, by the learning rule, and by the architecture itself. The weights are the adjustable parameters and, in that sense, a neural network is a parameterized system. The weighed sum of the inputs constitutes the activation of the neuron. The activation signal is passed through transfer function to produce a single output of the neuron. Transfer function introduces non-linearity to the network. During training, the inter-unit connections are optimized until the error in predictions is minimized and the network reaches the specified level of accuracy. Once the network is trained and tested it can be given new input information to predict the output. Many types of neural networks have been designed already and new ones are invented every week but all can be described by the transfer functions of their neurons, by the learning rule, and by the connection formula. ANN represents a promising modeling technique, especially for data sets having non-linear relationships which are frequently encountered in pharmaceutical processes. In terms of model specification, artificial neural networks require no knowledge of the data source but, since they often contain many weights that must be estimated, they require large training sets. In addition, ANNs can combine and incorporate both literature-based and experimental data to solve problems. The various applications of ANNs can be summarised into classification or pattern recognition, prediction and modeling. Supervised associating networks can be applied in pharmaceutical fields as an alternative to conventional response surface methodology. Unsupervised feature-extracting networks represent an alternative to principal component analysis. Non-adaptive unsupervised networks are able to reconstruct their patterns when presented with noisy samples and can be used for image recognition. The potential applications of ANN methodology in the pharmaceutical sciences range from interpretation of analytical data, drug and dosage form design through biopharmacy to clinical pharmacy.}
}

@article{Alzubaidi_Zhang_Humaidi_Al-Dujaili_Duan_Al-Shamma_Santamaría_Fadhel_Al-Amidie_Farhan_2021, title={Review of Deep Learning: Concepts, CNN Architectures, challenges, applications, Future Directions}, volume={8}, DOI={10.1186/s40537-021-00444-8}, number={1}, journal={Journal of Big Data}, author={Alzubaidi, Laith and Zhang, Jinglan and Humaidi, Amjad J. and Al-Dujaili, Ayad and Duan, Ye and Al-Shamma, Omran and Santamaría, J. and Fadhel, Mohammed A. and Al-Amidie, Muthana and Farhan, Laith}, year={2021}, month={Mar}} 

@misc{P._2025, title={What is a neural network & how does it work? ai guide}, url={https://blog.roboflow.com/what-is-a-neural-network/}, journal={Roboflow Blog}, publisher={Roboflow Blog}, author={P., Petru}, year={2025}, month={Jan}} 

@book{Gurney_1997, place={Oxford}, title={Introduction to neural networks Kevin Gurney}, publisher={Taylor & Francis}, author={Gurney, Kevin}, year={1997}} 

@misc{Roth_2016, title={Upenn}, url={https://www.cis.upenn.edu/~danroth/Teaching/CS446-17/LectureNotesNew/neuralnet1/main.pdf}, journal={Neural Networks}, author={Roth, Dan}, year={2016}} 

@misc{Weaver_2024, title={Perceptron 101: The Building Blocks of a neural network}, url={https://pub.aimind.so/perceptron-101-the-building-blocks-of-a-neural-network-496f6b9b3826}, journal={Medium}, publisher={AI Mind}, author={Weaver, Matthew}, year={2024}, month={Oct}} 

@article{cilimkovic2015neural,
  title={Neural networks and back propagation algorithm},
  author={Cilimkovic, Mirza},
  journal={Institute of Technology Blanchardstown, Blanchardstown Road North Dublin},
  volume={15},
  number={1},
  pages={18},
  year={2015}
}

@article{QIAN1999145,
title = {On the momentum term in gradient descent learning algorithms},
journal = {Neural Networks},
volume = {12},
number = {1},
pages = {145-151},
year = {1999},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(98)00116-6},
url = {https://www.sciencedirect.com/science/article/pii/S0893608098001166},
author = {Ning Qian},
keywords = {Momentum, Gradient descent learning algorithm, Damped harmonic oscillator, Critical damping, Learning rate, Speed of convergence},
abstract = {A momentum term is usually included in the simulations of connectionist learning algorithms. Although it is well known that such a term greatly improves the speed of learning, there have been few rigorous studies of its mechanisms. In this paper, I show that in the limit of continuous time, the momentum parameter is analogous to the mass of Newtonian particles that move through a viscous medium in a conservative force field. The behavior of the system near a local minimum is equivalent to a set of coupled and damped harmonic oscillators. The momentum term improves the speed of convergence by bringing some eigen components of the system closer to critical damping. Similar results can be obtained for the discrete time case used in computer simulations. In particular, I derive the bounds for convergence on learning-rate and momentum parameters, and demonstrate that the momentum term can increase the range of learning rate over which the system converges. The optimal condition for convergence is also analyzed.}
}

@article{ruder2016overview,
  title={An overview of gradient descent optimization algorithms},
  author={Ruder, Sebastian},
  journal={arXiv preprint arXiv:1609.04747},
  year={2016}
}

@misc{1370017282431050757,
author="Tieleman, T.",
title="Lecture 6.5‐rmsprop: Divide the Gradient by a Running Average of Its Recent Magnitude",
journal="COURSERA: Neural Networks for Machine Learning",
year="2012",
volume="4",
number="2",
pages="26",
URL="https://cir.nii.ac.jp/crid/1370017282431050757"
}

@misc{kingma2017adammethodstochasticoptimization,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1412.6980}, 
}

@inproceedings{NIPS2012_c399862d,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@ARTICLE{9451544,
  author={Li, Zewen and Liu, Fan and Yang, Wenjie and Peng, Shouheng and Zhou, Jun},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={A Survey of Convolutional Neural Networks: Analysis, Applications, and Prospects}, 
  year={2022},
  volume={33},
  number={12},
  pages={6999-7019},
  keywords={Convolutional neural networks;Feature extraction;Neurons;Deep learning;Computer vision;Computer vision;convolutional neural networks (CNNs);deep learning;deep neural networks},
  doi={10.1109/TNNLS.2021.3084827}} 

@misc{Riebesell_2022, title={Janosh Riebesell}, url={https://tikz.net/conv2d/}, journal={TikZ.net}, author={Riebesell, Janosh}, year={2022}, month={Apr}} 

@book{Goodfellow_Bengio_Courville_2018, place={Frechen}, title={Deep learning}, publisher={MITP}, author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron}, year={2018}} 

@article{Verschoof-van,
author = {Verschoof-van der Vaart, Wouter and Lambers, Karsten},
year = {2019},
month = {03},
pages = {31-40},
title = {Learning to Look at LiDAR: The Use of R-CNN in the Automated Detection of Archaeological Objects in LiDAR Data from the Netherlands},
volume = {2},
journal = {Journal of Computer Applications in Archaeology},
doi = {10.5334/jcaa.32}
}

@misc{schmidt2019recurrentneuralnetworksrnns,
      title={Recurrent Neural Networks (RNNs): A gentle Introduction and Overview}, 
      author={Robin M. Schmidt},
      year={2019},
      eprint={1912.05911},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1912.05911}, 
}

@article{fang-wei,
author = {Fang, Wei and Chen, Yupeng and Xue, Qiongying},
year = {2021},
month = {01},
pages = {97-110},
title = {Survey on Research of RNN-Based Spatio-Temporal Sequence Prediction Algorithms},
volume = {3},
journal = {Journal on Big Data},
doi = {10.32604/jbd.2021.016993}
}

@INBOOK{kolen,
  author={Kolen, John F. and Kremer, Stefan C.},
  booktitle={A Field Guide to Dynamical Recurrent Networks}, 
  title={Gradient Flow in Recurrent Nets: The Difficulty of Learning LongTerm Dependencies}, 
  year={2001},
  volume={},
  number={},
  pages={237-243},
  keywords={},
  doi={10.1109/9780470544037.ch14}}


@InProceedings{pmlr-v9-glorot10a,
  title = 	 {Understanding the difficulty of training deep feedforward neural networks},
  author = 	 {Glorot, Xavier and Bengio, Yoshua},
  booktitle = 	 {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {249--256},
  year = 	 {2010},
  editor = 	 {Teh, Yee Whye and Titterington, Mike},
  volume = 	 {9},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Chia Laguna Resort, Sardinia, Italy},
  month = 	 {13--15 May},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf},
  url = 	 {https://proceedings.mlr.press/v9/glorot10a.html},
  abstract = 	 {Whereas before 2006 it appears that deep multi-layer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future.  We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1.  Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence.}
}

@article{GAO2019279,
title = {Long short-term memory-based deep recurrent neural networks for target tracking},
journal = {Information Sciences},
volume = {502},
pages = {279-296},
year = {2019},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2019.06.039},
url = {https://www.sciencedirect.com/science/article/pii/S0020025519305778},
author = {Chang Gao and Junkun Yan and Shenghua Zhou and Pramod K. Varshney and Hongwei Liu},
keywords = {Target tracking, Deep neural network, Recurrent neural network, Long short-term memory},
abstract = {Target tracking is a difficult estimation problem due to target motion uncertainty and measurement origin uncertainty. In this paper, we consider the target tracking problem in the presence of only target motion uncertainty. The traditional approaches to address this uncertainty, such as multiple model approaches, can suffer performance degradation when there is a model mismatch. The statistical accuracy of conventional model-based methods is also usually limited because of the measurement errors and insufficient data for the estimation. In this paper, deep neural network-based methods are proposed to handle target motion uncertainty due to their strong capability of fitting any mapping as long as there are sufficient training data. Specifically, a recurrent neural network-based structure is proposed to estimate the true states that is consistent with the sequential manner of target tracking. In addition, it is expected that better performance will be achieved due to access to true states during the training of the networks. We propose two networks that are based on different principles and are capable of real-time tracking. An approach to further reduce the computational load is also introduced. Simulation results show that the proposed methods can handle the target motion uncertainty well and provide better estimation accuracy.}
}

@article{Hochreiter,
author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
year = {1997},
month = {11},
pages = {1735-1780},
title = {Long Short-Term Memory},
volume = {9},
journal = {Neural Computation},
doi = {10.1162/neco.1997.9.8.1735}
}

@article{ALSELWI2024102068,
title = {RNN-LSTM: From applications to modeling techniques and beyond—Systematic review},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {36},
number = {5},
pages = {102068},
year = {2024},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2024.102068},
url = {https://www.sciencedirect.com/science/article/pii/S1319157824001575},
author = {Safwan Mahmood Al-Selwi and Mohd Fadzil Hassan and Said Jadid Abdulkadir and Amgad Muneer and Ebrahim Hamid Sumiea and Alawi Alqushaibi and Mohammed Gamal Ragab},
keywords = {Machine learning, Deep learning, Recurrent neural networks, Long short-term memory, Weights initialization, Weights optimization, Systematic literature review},
abstract = {Long Short-Term Memory (LSTM) is a popular Recurrent Neural Network (RNN) algorithm known for its ability to effectively analyze and process sequential data with long-term dependencies. Despite its popularity, the challenge of effectively initializing and optimizing RNN-LSTM models persists, often hindering their performance and accuracy. This study presents a systematic literature review (SLR) using an in-depth four-step approach based on the PRISMA methodology, incorporating peer-reviewed articles spanning 2018–2023. It aims to address how weight initialization and optimization techniques can bolster RNN-LSTM performance. This SLR offers a detailed overview across various applications and domains, and stands out by comprehensively analyzing modeling techniques, datasets, evaluation metrics, and programming languages associated with these networks. The findings of this SLR provide a roadmap for researchers and practitioners to enhance RNN-LSTM networks and achieve superior results.}
}

@article{WEI2021453,
title = {Machine learning for pore-water pressure time-series prediction: Application of recurrent neural networks},
journal = {Geoscience Frontiers},
volume = {12},
number = {1},
pages = {453-467},
year = {2021},
issn = {1674-9871},
doi = {https://doi.org/10.1016/j.gsf.2020.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S1674987120301134},
author = {Xin Wei and Lulu Zhang and Hao-Qing Yang and Limin Zhang and Yang-Ping Yao},
keywords = {Pore-water pressure, Slope, Multi-layer perceptron, Recurrent neural networks, Long short-term memory, Gated recurrent unit},
abstract = {Knowledge of pore-water pressure (PWP) variation is fundamental for slope stability. A precise prediction of PWP is difficult due to complex physical mechanisms and in situ natural variability. To explore the applicability and advantages of recurrent neural networks (RNNs) on PWP prediction, three variants of RNNs, i.e., standard RNN, long short-term memory (LSTM) and gated recurrent unit (GRU) are adopted and compared with a traditional static artificial neural network (ANN), i.e., multi-layer perceptron (MLP). Measurements of rainfall and PWP of representative piezometers from a fully instrumented natural slope in Hong Kong are used to establish the prediction models. The coefficient of determination (R2) and root mean square error (RMSE) are used for model evaluations. The influence of input time series length on the model performance is investigated. The results reveal that MLP can provide acceptable performance but is not robust. The uncertainty bounds of RMSE of the MLP model range from 0.24 kPa to 1.12 kPa for the selected two piezometers. The standard RNN can perform better but the robustness is slightly affected when there are significant time lags between PWP changes and rainfall. The GRU and LSTM models can provide more precise and robust predictions than the standard RNN. The effects of the hidden layer structure and the dropout technique are investigated. The single-layer GRU is accurate enough for PWP prediction, whereas a double-layer GRU brings extra time cost with little accuracy improvement. The dropout technique is essential to overfitting prevention and improvement of accuracy.}
}

@misc{bahdanau2016neuralmachinetranslationjointly,
      title={Neural Machine Translation by Jointly Learning to Align and Translate}, 
      author={Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
      year={2016},
      eprint={1409.0473},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1409.0473}, 
}

@misc{vaswani2023attentionneed,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762}, 
}

@article{NIU202148,
title = {A review on the attention mechanism of deep learning},
journal = {Neurocomputing},
volume = {452},
pages = {48-62},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.03.091},
url = {https://www.sciencedirect.com/science/article/pii/S092523122100477X},
author = {Zhaoyang Niu and Guoqiang Zhong and Hui Yu},
keywords = {Attention mechanism, Deep learning, Recurrent Neural Network (RNN), Convolutional Neural Network (CNN), Encoder-decoder, Unified attention model, Computer vision applications, Natural language processing applications},
abstract = {Attention has arguably become one of the most important concepts in the deep learning field. It is inspired by the biological systems of humans that tend to focus on the distinctive parts when processing large amounts of information. With the development of deep neural networks, attention mechanism has been widely used in diverse application domains. This paper aims to give an overview of the state-of-the-art attention models proposed in recent years. Toward a better general understanding of attention mechanisms, we define a unified model that is suitable for most attention structures. Each step of the attention mechanism implemented in the model is described in detail. Furthermore, we classify existing attention models according to four criteria: the softness of attention, forms of input feature, input representation, and output representation. Besides, we summarize network architectures used in conjunction with the attention mechanism and describe some typical applications of attention mechanism. Finally, we discuss the interpretability that attention brings to deep learning and present its potential future trends.}
}

@article{Brauwers_2023,
   title={A General Survey on Attention Mechanisms in Deep Learning},
   volume={35},
   ISSN={2326-3865},
   url={http://dx.doi.org/10.1109/TKDE.2021.3126456},
   DOI={10.1109/tkde.2021.3126456},
   number={4},
   journal={IEEE Transactions on Knowledge and Data Engineering},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Brauwers, Gianni and Frasincar, Flavius},
   year={2023},
   month=apr, pages={3279–3298} }


@Article{Tsunashima-2019,
AUTHOR = {Tsunashima, Hitoshi},
TITLE = {Condition Monitoring of Railway Tracks from Car-Body Vibration Using a Machine Learning Technique},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {13},
ARTICLE-NUMBER = {2734},
URL = {https://www.mdpi.com/2076-3417/9/13/2734},
ISSN = {2076-3417},
ABSTRACT = {A track condition monitoring system that uses a compact on-board sensing device has been developed and applied for track condition monitoring of regional railway lines in Japan. Monitoring examples show that the system is effective for regional railway operators. A classifier for track faults has been developed to detect track fault automatically. Simulation studies using SIMPACK and field tests were carried out to detect and isolate the track faults from car-body vibration. The results show that the feature of track faults is extracted from car-body vibration and classified from proposed feature space using machine learning techniques.},
DOI = {10.3390/app9132734}
}

@article{PIRES2024107191,
title = {Measuring vertical track irregularities from instrumented heavy haul railway vehicle data using machine learning},
journal = {Engineering Applications of Artificial Intelligence},
volume = {127},
pages = {107191},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.107191},
url = {https://www.sciencedirect.com/science/article/pii/S0952197623013751},
author = {A.C. Pires and M.C.A. Viana and L.M. Scaramussa and G.F.M. Santos and P.G. Ramos and A.A. Santos},
keywords = {Machine learning, Instrumented railway vehicle, Heavy haul railway, Track irregularities, Multibody simulation, Railway condition monitoring},
abstract = {This paper proposes a data-driven approach to estimating geometric track irregularities from instrumented railway vehicle (IRV) data. Machine learning is used to find the nonlinear mapping between IRV data and track irregularities. A dynamic model of the BRA1 railway vehicle was used to generate an artificial dataset that contains variables that are measured by the real BRA1 IRV and other variables measured by IRVs found in the literature. An extensive data analysis step was done to verify if the current instrumentation of the BRA1 IRV is sufficient for obtaining both lateral and vertical track irregularities. Feature engineering based on wagon movements, signal integration and time domain statistical metrics were applied to extract features and then the best features were selected using a wrapper method. Eight different regression ML models were trained and optimized after the feature selection using Optuna. The results show that, with the current instrumentation of the BRA1 IRV, obtaining lateral track irregularities is unlikely due to low correlation, however, vertical irregularities can be obtained with a root mean squared error (RMSE) of 0.556 mm. With postprocessing, the RMSE was further reduced to 0.410 mm.}
}

@article{GHIASI2025109516,
title = {Unsupervised domain adaptation for drive-by condition monitoring of multiple railway tracks},
journal = {Engineering Applications of Artificial Intelligence},
volume = {139},
pages = {109516},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.109516},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624016749},
author = {Ramin Ghiasi and Nicolas Lestoille and Cassandre Diaine and Abdollah Malekjafarian},
keywords = {Unsupervised domain adaptation, Data driven, Track geometry, Drive-by monitoring, Harmotrack project},
abstract = {Monitoring railway tracks through drive-by vibration data collected by in-service trains offers a cost-effective and adaptable solution for inspecting multiple railway lines. However, numerous existing drive-by monitoring methods rely on supervised learning models, necessitating extensive labelled data for each line. In this paper, a novel framework is proposed based on Unsupervised Domain Adaptation (UDA) concept which facilitates the transfer of a geometric defects diagnosis model learned from one line to a new line without the need for any labelled data from the new line. The proposed framework learns the dynamic-based features that are sensitive to damage and also invariant to different railway tracks. It comprises three components: data pre-processing, UDA implementation, and damage diagnosis. The framework uses the data from the source domain, including corresponding labels, as well as the unlabelled data from the target domain as input. The outputs of the framework consist of the predicted labels for the target domain. The performance of the proposed framework is evaluated using a comprehensive dataset of field measurements of a high-speed train passing 4 different lines within the French high-speed rail network. The proposed UDA framework is implemented using four common UDA algorithms including Information-Theoretical Learning (ITL), Geodesic Flow Kernel (GFK), Transfer Component Analysis (TCA), and Subspace Alignment (SA). The results show that the proposed framework has a 14% increase in the anomaly detection accuracy compared to traditional unsupervised learning methods in which UDA is not used. Furthermore, this study investigates the impact of incorporating a percentage of target data labels during training (semi-supervised domain adaptation), along with various sensor layouts and different tuning parameters, on the accuracy of the proposed approach. The results show that the proposed framework can significantly facilitate the monitoring of railway track conditions using the data collected by in-service trains which could be great interest of railway owners.}
}

@article{Hironori_ONO202322-00239,
  title={Development and operation of a system for diagnosing the condition of regional railways tracks},
  author={Hironori ONO and Hitoshi TSUNASHIMA and Tetsuya TAKATA and Seigo OGATA},
  journal={Mechanical Engineering Journal},
  volume={10},
  number={3},
  pages={22-00239-22-00239},
  year={2023},
  doi={10.1299/mej.22-00239}
}

@article{Balouchi02092021,
author = {F. Balouchi and A. Bevan and R. Formston},
title = {Development of railway track condition monitoring from multi-train in-service vehicles},
journal = {Vehicle System Dynamics},
volume = {59},
number = {9},
pages = {1397--1417},
year = {2021},
publisher = {Taylor \& Francis},
doi = {10.1080/00423114.2020.1755045},
URL = {https://doi.org/10.1080/00423114.2020.1755045},
eprint = {https://doi.org/10.1080/00423114.2020.1755045}
}

@Article{vibration7040049,
AUTHOR = {Tsunashima, Hitoshi and Yagura, Nozomu},
TITLE = {Railway Track Irregularity Estimation Using Car Body Vibration: A Data-Driven Approach for Regional Railway},
JOURNAL = {Vibration},
VOLUME = {7},
YEAR = {2024},
NUMBER = {4},
PAGES = {928--948},
URL = {https://www.mdpi.com/2571-631X/7/4/49},
ISSN = {2571-631X},
ABSTRACT = {Track and preventive maintenance are necessary for the safe and comfortable operation of railways. Track displacement measured by track inspection vehicles or trolleys has been primarily used for track management. Thus, vibration data measured in in-service vehicles have not been extensively used for track management. In this study, we propose a new technique for estimating track irregularities from measured car body vibration for track management. The correlation between track irregularity and car body vibration was analysed using a multibody dynamics simulation of travelling rail vehicles. Gaussian process regression (GPR) was applied to the track irregularity and car body vibration data obtained from the simulation, and a method was proposed to estimate the track irregularities from the constructed regression model. The longitudinal-level, alignment, and cross-level irregularities were estimated from the measured car body vibrations and travelling speeds on a regional railway, and the results were compared with the actual track irregularity data. The results showed that the proposed method is applicable for track irregularity management in regional railways.},
DOI = {10.3390/vibration7040049}
}

@article{Sansiñena26032025,
author = {Adrián Sansinena and Borja Rodríguez-Arana and Saioa Arrizabalaga},
title = {A systematic review of acceleration-based estimation of railway track quality},
journal = {Vehicle System Dynamics},
volume = {0},
number = {0},
pages = {1--28},
year = {2025},
publisher = {Taylor \& Francis},
doi = {10.1080/00423114.2025.2483972},
URL = {https://doi.org/10.1080/00423114.2025.2483972},
eprint = {https://doi.org/10.1080/00423114.2025.2483972}
}

@article{DEROSA2019606,
title = {Estimation of lateral and cross alignment in a railway track based on vehicle dynamics measurements},
journal = {Mechanical Systems and Signal Processing},
volume = {116},
pages = {606-623},
year = {2019},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2018.06.041},
url = {https://www.sciencedirect.com/science/article/pii/S0888327018303790},
author = {Anna {De Rosa} and Stefano Alfi and Stefano Bruni},
keywords = {Railway condition monitoring, Input estimation methods, Track irregularity identification, Onboard measurements},
abstract = {Monitoring the condition of the infrastructure based on measurements coming from in-service trains is a recent trend in the policies of railway infrastructure managers and is seen as a major factor to reduce maintenance costs retaining the present levels of passengers’ ride comfort and availability of the lines. Aim of this paper is to develop and assess model-based methods for the identification of geometric track irregularities from acceleration measurements taken on-board vehicles travelling on the track. In particular, the paper focusses on the identification of lateral alignment irregularities, a yet unsolved problem which turns out to be much more demanding compared to the identification of longitudinal level irregularities due to the relative wheel-rail motion in lateral direction which occurs on account of the peculiar geometry of wheel-rail contact. The paper presents three different approaches to the estimation of the lateral and cross-level track irregularities, one defined in the frequency domain and two in the time domain. For each method, an assessment is performed based on numerical experiments in which virtual measurements from vehicle-mounted sensors are obtained by means of numerical simulations performed using a multi-body model of a railway vehicle. For the method defined in the frequency domain, a first application to line measurements is presented.}
}

@article{DeRosa2021,
author = {A De Rosa and R Kulkarni and A Qazizadeh and M Berg and E Di Gialleonardo and A Facchinetti and S Bruni},
title ={Monitoring of lateral and cross level track geometry irregularities through onboard vehicle dynamics measurements using machine learning classification algorithms},
journal = {Proceedings of the Institution of Mechanical Engineers, Part F: Journal of Rail and Rapid Transit},
volume = {235},
number = {1},
pages = {107-120},
year = {2021},
doi = {10.1177/0954409720906649},
URL = {https://doi.org/10.1177/0954409720906649},
eprint = {https://doi.org/10.1177/0954409720906649},
abstract = { In recent years, significant studies have focused on monitoring the track geometry irregularities through measurements of vehicle dynamics acquired onboard. Most of these studies analyse the vertical irregularity and the vertical vehicle dynamics since the lateral direction is much more challenging due to the non-linearities caused by the contact between the wheels and the rails. In the present work, a machine learning-based fault classifier for the condition monitoring of track irregularities in the lateral direction is proposed. The classifiers are trained with a dataset composed of numerical simulation results and validated with a dataset of measurements acquired by a diagnostic vehicle on the straight track sections of a high-speed line (300 km/h). Classifiers based on decision tree, linear and Gaussian support vector machine algorithms are developed and compared in terms of performance: good results are achieved with the three algorithms, especially with the Gaussian support vector machine. Even though classifiers are data driven, they retain the essence of lateral dynamics. }
}